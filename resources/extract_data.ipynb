{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import gspread\n",
    "import json\n",
    "import pandas as pd\n",
    "import uuid\n",
    "from geopy.geocoders import Nominatim\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authenticate and connect to google sheets\n",
    "scope = [\n",
    "    \"https://spreadsheets.google.com/feeds\",\n",
    "    \"https://www.googleapis.com/auth/drive\",\n",
    "]\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(\"api_keys.json\", scope)\n",
    "client = gspread.authorize(creds)\n",
    "spreadsheet = client.open_by_key(\"12L4EkdRqaQ_e42fGHWaTmgCeqQrNgjTfoeAEc5AB6tw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from google sheet\n",
    "overview_sheet = spreadsheet.worksheet(\"Overview\")\n",
    "overview_data = overview_sheet.get_all_records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert lists stored as strings into actual lists\n",
    "def parse_list(value):\n",
    "    if isinstance(value, str) and value.strip():\n",
    "        return [item.strip() for item in value.split(\",\")]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default values for missing fields\n",
    "defaults = {\n",
    "    \"photos\": [],\n",
    "    \"description\": \"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data\n",
    "for entry in overview_data:\n",
    "    # parse and clean up photos list\n",
    "    raw_photos = entry.get(\"photos\", \"\")\n",
    "    entry[\"photos\"] = [photo.strip('[]\"') for photo in parse_list(raw_photos)]\n",
    "    \n",
    "    # set default values for missing keys\n",
    "    for key, default in defaults.items():\n",
    "        entry.setdefault(key, default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travel data successfully saved!\n"
     ]
    }
   ],
   "source": [
    "# save as JSON for JavaScript map\n",
    "with open(\"./data/overview.json\", \"w\") as file:\n",
    "    json.dump(overview_data, file, indent=2)\n",
    "\n",
    "print(\"Travel data successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location and Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Activity data\n",
    "activity_sheet = spreadsheet.worksheet(\"Activity\")\n",
    "activity_data = pd.DataFrame(activity_sheet.get_all_records())\n",
    "\n",
    "# add activity IDs\n",
    "activity_data['activity_id'] = [\n",
    "    str(uuid.uuid4()) if pd.isna(id) or id == \"\" else id for id in activity_data.get('activity_id', [])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Location data\n",
    "location_sheet = spreadsheet.worksheet(\"Location\")\n",
    "location_data = pd.DataFrame(location_sheet.get_all_records())\n",
    "\n",
    "# add unique location IDs if missing\n",
    "location_data['location_id'] = [\n",
    "    str(uuid.uuid4()) if pd.isna(id) or id == \"\" else id for id in location_data['location_id']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add any new locations from Activity data to the Location sheet\n",
    "\n",
    "# get new locations\n",
    "existing_locations = set(location_data['name'])\n",
    "new_locations = activity_data[~activity_data['location_name'].isin(existing_locations)]\n",
    "\n",
    "new_locations_to_add = []\n",
    "\n",
    "# add new locations to Location sheet\n",
    "for _, row in new_locations.iterrows():\n",
    "    new_location_id = str(uuid.uuid4())  # new unique location_id\n",
    "    new_location = {\n",
    "        'name': row['location_name'],\n",
    "        'location_id': new_location_id,\n",
    "        'location': row['location_name'],\n",
    "        'lat': \"\",  # null placeholder\n",
    "        'lng': \"\"   # null placeholder\n",
    "    }\n",
    "    new_locations_to_add.append(new_location)\n",
    "\n",
    "# append new locations to the existing DataFrame\n",
    "new_locations_df = pd.DataFrame(new_locations_to_add)\n",
    "location_data = pd.concat([location_data, new_locations_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign Activity.location_id, by matching Activity.location_name with Location.name\n",
    "\n",
    "# create dict for mapping location names to IDs\n",
    "location_name_to_id = dict(zip(location_data['name'], location_data['location_id']))\n",
    "# assign location IDs to activities, using the mapping dict\n",
    "activity_data['location_id'] = activity_data['location_name'].map(location_name_to_id)\n",
    "\n",
    "# print unmatched location names\n",
    "unmatched_activities = activity_data[activity_data['location_id'].isna()]\n",
    "if not unmatched_activities.empty:\n",
    "    print(\"Unmatched location names:\")\n",
    "    print(unmatched_activities[['activity_id', 'location_name']])\n",
    "    # default blank string for unmatched location IDs\n",
    "    activity_data['location_id'].fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geocode locations\n",
    "geolocator = Nominatim(user_agent=\"geoapi\", timeout=10)\n",
    "\n",
    "# cache for geocoding results, to avoid repeated requests / rate limits\n",
    "try:\n",
    "    with open('./data/geocode_cache.json', 'r') as cache_file:\n",
    "        geocode_cache = json.load(cache_file)\n",
    "except FileNotFoundError:\n",
    "    geocode_cache = {}\n",
    "\n",
    "def geocode_location(location_name):\n",
    "    # check cache first\n",
    "    if location_name in geocode_cache:\n",
    "        return geocode_cache[location_name]['lat'], geocode_cache[location_name]['lng']\n",
    "    try:\n",
    "        location = geolocator.geocode(location_name)\n",
    "        if location:\n",
    "            lat_lng = {'lat': location.latitude, 'lng': location.longitude}\n",
    "            geocode_cache[location_name] = lat_lng  # cache result\n",
    "            return lat_lng['lat'], lat_lng['lng']\n",
    "        else:\n",
    "            return pd.Series([None, None])\n",
    "    except Exception as e:\n",
    "        print(f\"Error geocoding {location_name}: {e}\")\n",
    "        return pd.Series([None, None])\n",
    "\n",
    "# geocode if lat/lng are missing\n",
    "for index, row in location_data.iterrows():\n",
    "    if not row['lat'] or not row['lng'] or pd.isna(row['lat']) or pd.isna(row['lng']):\n",
    "        lat, lng = geocode_location(row['location'])\n",
    "        print(f\"Geocoding {row['location']}...\")\n",
    "        location_data.at[index, 'lat'] = lat\n",
    "        location_data.at[index, 'lng'] = lng\n",
    "        \n",
    "        # save progress every 5 requests\n",
    "        if index % 5 == 0:\n",
    "            location_data.to_csv('./data/Location.csv', index=False)\n",
    "            with open('./data/geocode_cache.json', 'w') as cache_file:\n",
    "                json.dump(geocode_cache, cache_file) \n",
    "        \n",
    "        # for Nominatim rate limits\n",
    "        # sleep(1)\n",
    "\n",
    "# save final cache\n",
    "with open('./data/geocode_cache.json', 'w') as cache_file:\n",
    "    json.dump(geocode_cache, cache_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location and Activity data successfully saved!\n"
     ]
    }
   ],
   "source": [
    "# save updated data to CSV for JavaScript map\n",
    "location_data.to_csv('./data/Location.csv', index=False)\n",
    "activity_data.to_csv('./data/Activity.csv', index=False)\n",
    "\n",
    "print(\"Location and Activity data successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully uploaded to Google Sheets!\n"
     ]
    }
   ],
   "source": [
    "# upload updated data to Google Sheets\n",
    "\n",
    "# replace NaN or None values with empty strings for Google Sheets compatibility\n",
    "location_data = location_data.fillna(\"\")\n",
    "\n",
    "# convert dfs to lists of lists\n",
    "location_data_list = [location_data.columns.values.tolist()] + location_data.values.tolist()\n",
    "activity_data_list = [activity_data.columns.values.tolist()] + activity_data.values.tolist()\n",
    "\n",
    "# print(location_data_list)\n",
    "\n",
    "# upload Location sheet\n",
    "location_sheet = spreadsheet.worksheet(\"Location\")\n",
    "try:\n",
    "    location_sheet.clear()  # clear existing data\n",
    "    location_sheet.update(values=location_data_list, range_name='A1')  # upload new data\n",
    "except Exception as e:\n",
    "    print(f\"Error updating Location sheet: {e}\")\n",
    "\n",
    "# upload Activity sheet\n",
    "activity_sheet = spreadsheet.worksheet(\"Activity\")\n",
    "try:\n",
    "    activity_sheet.clear()  # clear existing data\n",
    "    activity_sheet.update(values=activity_data_list, range_name='A1')  # upload new data\n",
    "except Exception as e:\n",
    "    print(f\"Error updating Activity sheet: {e}\")\n",
    "\n",
    "print(\"Data successfully uploaded to Google Sheets!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # bounding box for St. John, USVI\n",
    "# # viewbox = [[18.3839, -64.7922], [18.3080, -64.6823]]\n",
    "\n",
    "# # # bounding box for Anegada, British Virgin Islands\n",
    "# # viewbox = [[18.7666, -64.4050], [18.6833, -64.2694]]\n",
    "\n",
    "# # Bounding box for Cabo Pulmo, Mexico\n",
    "# viewbox = [[23.4700, -109.4500], [23.4000, -109.3500]]\n",
    "\n",
    "# # example queries\n",
    "# queries = [\"beach\", \"bay\", \"park\", \"trail\"]\n",
    "\n",
    "# # geocode each query within the bounding box\n",
    "# for query in queries:\n",
    "#     location = geolocator.geocode(query, viewbox=viewbox, bounded=True)\n",
    "#     if location:\n",
    "#         print(f\"{query}: {location.latitude}, {location.longitude} - {location.address}\")\n",
    "#     else:\n",
    "#         print(f\"{query}: Location not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import overpy\n",
    "\n",
    "# # initialize Overpass API\n",
    "# api = overpy.Overpass()\n",
    "\n",
    "# # all points of interest in St. John, USVI\n",
    "# query = \"\"\"\n",
    "# [out:json];\n",
    "# (\n",
    "#   node[\"name\"](18.3080,-64.7922,18.3839,-64.6823);\n",
    "#   way[\"name\"](18.3080,-64.7922,18.3839,-64.6823);\n",
    "#   relation[\"name\"](18.3080,-64.7922,18.3839,-64.6823);\n",
    "# );\n",
    "# out center;\n",
    "# \"\"\"\n",
    "\n",
    "# # run the query\n",
    "# result = api.query(query)\n",
    "\n",
    "# # print results\n",
    "# for node in result.nodes:\n",
    "#     print(f\"Node: {node.tags.get('name', 'Unnamed')} - {node.lat}, {node.lon}\")\n",
    "\n",
    "# for way in result.ways:\n",
    "#     print(f\"Way: {way.tags.get('name', 'Unnamed')}\")\n",
    "\n",
    "# for relation in result.relations:\n",
    "#     print(f\"Relation: {relation.tags.get('name', 'Unnamed')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
