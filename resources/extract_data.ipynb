{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import gspread\n",
    "import json\n",
    "import geojson\n",
    "import pandas as pd\n",
    "import uuid\n",
    "# import requests\n",
    "from pathlib import Path\n",
    "from geographiclib.geodesic import Geodesic\n",
    "import openrouteservice\n",
    "from geopy.geocoders import Nominatim\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Overview](#overview)\n",
    "- [Activity](#activity)\n",
    "- [Routes](#routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authenticate and connect to google sheets\n",
    "scope = [\n",
    "    \"https://spreadsheets.google.com/feeds\",\n",
    "    \"https://www.googleapis.com/auth/drive\",\n",
    "]\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(\"api_keys.json\", scope)\n",
    "client = gspread.authorize(creds)\n",
    "spreadsheet = client.open_by_key(\"12L4EkdRqaQ_e42fGHWaTmgCeqQrNgjTfoeAEc5AB6tw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "[Back to Top](#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from google sheet\n",
    "overview_sheet = spreadsheet.worksheet(\"Overview\")\n",
    "overview_data = overview_sheet.get_all_records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert lists stored as strings into actual lists\n",
    "def parse_list(value):\n",
    "    if isinstance(value, str) and value.strip():\n",
    "        return [item.strip() for item in value.split(\",\")]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default values for missing fields\n",
    "# pretty sure this is extraneous\n",
    "defaults = {\n",
    "    \"photos\": [],\n",
    "    \"description\": \"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data\n",
    "for entry in overview_data:\n",
    "    # parse and clean up photos list\n",
    "    raw_photos = entry.get(\"photos\", \"\")\n",
    "    entry[\"photos\"] = [photo.strip('[]\"') for photo in parse_list(raw_photos)]\n",
    "\n",
    "    # set default values for missing keys\n",
    "    # I don't think I need this\n",
    "    for key, default in defaults.items():\n",
    "        entry.setdefault(key, default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travel data successfully saved!\n"
     ]
    }
   ],
   "source": [
    "# save as JSON for JavaScript map\n",
    "with open(\"../docs/resources/data/overview.json\", \"w\") as file:\n",
    "    json.dump(overview_data, file, indent=2)\n",
    "\n",
    "print(\"Travel data successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity\n",
    "\n",
    "[Back to Top](#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Activity data\n",
    "activity_sheet = spreadsheet.worksheet(\"Activity\")\n",
    "activity_data = pd.DataFrame(activity_sheet.get_all_records())\n",
    "\n",
    "# add activity IDs\n",
    "activity_data[\"activity_id\"] = [\n",
    "    str(uuid.uuid4()) if pd.isna(id) or id == \"\" else id\n",
    "    for id in activity_data.get(\"activity_id\", [])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geocode locations missing lat/lng\n",
    "geolocator = Nominatim(user_agent=\"geoapi\", timeout=10)\n",
    "\n",
    "# cache for geocoding results, to avoid repeated requests / rate limits\n",
    "try:\n",
    "    with open(\"./geocode_cache.json\", \"r\") as cache_file:\n",
    "        geocode_cache = json.load(cache_file)\n",
    "except FileNotFoundError:\n",
    "    geocode_cache = {}\n",
    "\n",
    "\n",
    "def geocode_location(location_name):\n",
    "    # check cache first\n",
    "    if location_name in geocode_cache:\n",
    "        return geocode_cache[location_name][\"lat\"], geocode_cache[location_name][\"lng\"]\n",
    "    try:\n",
    "        location = geolocator.geocode(location_name)\n",
    "        if location:\n",
    "            lat_lng = {\"lat\": location.latitude, \"lng\": location.longitude}\n",
    "            geocode_cache[location_name] = lat_lng  # cache result\n",
    "            return lat_lng[\"lat\"], lat_lng[\"lng\"]\n",
    "        else:\n",
    "            print(f\"No lat/lng found for location: {location_name}\")\n",
    "            return pd.Series([None, None])\n",
    "    except Exception as e:\n",
    "        print(f\"Error geocoding {location_name}: {e}\")\n",
    "        return pd.Series([None, None])\n",
    "\n",
    "\n",
    "# geocode if lat/lng are missing\n",
    "for index, row in activity_data.iterrows():\n",
    "    if not row[\"lat\"] or not row[\"lng\"] or pd.isna(row[\"lat\"]) or pd.isna(row[\"lng\"]):\n",
    "        lat, lng = geocode_location(row[\"location\"])\n",
    "        print(f\"Geocoding {row['location']}...\")\n",
    "        activity_data.at[index, \"lat\"] = lat\n",
    "        activity_data.at[index, \"lng\"] = lng\n",
    "\n",
    "        # save progress every 5 requests\n",
    "        if index % 5 == 0:\n",
    "            activity_data.to_csv(\"../docs/resources/data/Location.csv\", index=False)\n",
    "            with open(\"./geocode_cache.json\", \"w\") as cache_file:\n",
    "                json.dump(geocode_cache, cache_file)\n",
    "\n",
    "        # for Nominatim rate limits\n",
    "        # sleep(1)\n",
    "\n",
    "# save final cache\n",
    "with open(\"./geocode_cache.json\", \"w\") as cache_file:\n",
    "    json.dump(geocode_cache, cache_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity data successfully saved to csv!\n"
     ]
    }
   ],
   "source": [
    "# save updated data to csv for JavaScript map\n",
    "activity_data.to_csv(\"../docs/resources/data/activity.csv\", index=False)\n",
    "\n",
    "print(\"Activity data successfully saved to csv!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully uploaded to Google Sheets!\n"
     ]
    }
   ],
   "source": [
    "# upload updated data to Google Sheets\n",
    "\n",
    "# replace NaN or None values with empty strings for Google Sheets compatibility\n",
    "activity_data = activity_data.fillna(\"\")\n",
    "\n",
    "# convert df to lists of lists\n",
    "activity_data_list = [\n",
    "    activity_data.columns.values.tolist()\n",
    "] + activity_data.values.tolist()\n",
    "\n",
    "# upload Activity sheet\n",
    "activity_sheet = spreadsheet.worksheet(\"Activity\")\n",
    "try:\n",
    "    activity_sheet.clear()  # clear existing data\n",
    "    activity_sheet.update(values=activity_data_list, range_name=\"A1\")  # upload new data\n",
    "except Exception as e:\n",
    "    print(f\"Error updating Activity sheet: {e}\")\n",
    "\n",
    "print(\"Data successfully uploaded to Google Sheets!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Routes\n",
    "\n",
    "[Back to top](#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load route data\n",
    "route_sheet = spreadsheet.worksheet(\"Routes\")\n",
    "route_data = pd.DataFrame(route_sheet.get_all_records())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add hiking routes if in Activity with geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Activity geojson to Routes\n",
    "for index, row in activity_data.iterrows():\n",
    "    # if hiking activities with a route_path not in Routes.filename\n",
    "    if (\n",
    "        row[\"activity_type\"] == \"hiking\"  # Activity type is hiking\n",
    "        and row[\"route_path\"]  # Activity has a route_path\n",
    "        and row[\"route_path\"] not in route_data[\"filename\"].values  # route_path not in Routes.filename\n",
    "    ):\n",
    "        # add new route to Routes\n",
    "        new_route = {\n",
    "            \"start_location\": row[\"name\"],  # Activity.name\n",
    "            \"end_location\": row[\"name\"],  # Activity.name\n",
    "            \"transport_mode\": \"hike\",  # Fixed value\n",
    "            \"filename\": row[\"route_path\"],  # Activity.route_path\n",
    "        }\n",
    "        route_data = pd.concat([route_data, pd.DataFrame([new_route])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add route IDs\n",
    "route_data[\"route_id\"] = [\n",
    "    str(uuid.uuid4()) if pd.isna(id) or id == \"\" else id\n",
    "    for id in route_data.get(\"route_id\", [])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generates Airplane great circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping non-plane route: Jaipur -> New Delhi\n",
      "Skipping non-plane route: New Delhi -> Amritsar\n",
      "Skipping non-plane route: New Delhi -> Agra\n",
      "Skipping non-plane route: Jaipur -> Agra\n",
      "Skipping non-plane route: Calicut -> Fort Cochin\n",
      "Skipping non-plane route: Fort Cochin -> Alleppey\n",
      "Skipping non-plane route: Allepy -> Bangalore\n",
      "Skipping non-plane route: Bangalore -> Mysore\n",
      "Skipping non-plane route: Mysore -> Gokarna\n",
      "Skipping non-plane route: Gokarna -> Panaji\n",
      "Skipping non-plane route: Bangalore -> Anjuna\n",
      "Skipping non-plane route: Anjuna -> Panaji\n",
      "Skipping non-plane route: Jaipur -> Pushkar\n",
      "Skipping non-plane route: Jaipur -> Jodhpur\n",
      "Skipping non-plane route: Jaipur -> Alwar\n",
      "Skipping non-plane route: Jaipur -> Bikaner\n",
      "Skipping non-plane route: Jaipur -> Udaipur\n",
      "Skipping non-plane route: Udaipur -> Jodhpur\n",
      "Skipping non-plane route: Amritsar -> Manali, HImachal Pradesh\n",
      "Skipping non-plane route: Manali, HImachal Pradesh -> New Delhi\n",
      "Skipping non-plane route: Table Mountain -> Table Mountain\n",
      "Skipping non-plane route: Mt Mansfield -> Mt Mansfield\n",
      "Skipping non-plane route: St John -> St John\n",
      "Skipping non-plane route: Agra -> Jagdalpur\n",
      "Skipping non-plane route: Amsterdam -> Alkmaar\n",
      "Skipping non-plane route: Amsterdam -> Utrecht\n",
      "Skipping non-plane route: Ediburgh -> North Berwick\n",
      "Skipping non-plane route: Jaipur -> Jodhpur\n",
      "Skipping non-plane route: Jaipur -> New Delhi\n",
      "Skipping non-plane route: London -> Bath\n",
      "Skipping non-plane route: London -> Edinburgh\n",
      "Skipping non-plane route: Maastricht -> Amsterdam\n",
      "Skipping non-plane route: New Delhi -> Amritsar\n",
      "Skipping non-plane route: Sittard -> Eindhoven\n",
      "Skipping non-plane route: Sittard -> Nijmegen\n",
      "Skipping non-plane route: Sittard -> Rotterdam\n",
      "Skipping non-plane route: Washington, DC -> Essex, Vermont\n",
      "Skipping non-plane route: Jagdalpur -> Visakhapatnam\n",
      "Skipping non-plane route: Ollantaytambo -> Machu Picchu\n",
      "Skipping non-plane route: Cusco -> Puno\n",
      "Skipping non-plane route: Edinburgh -> Llandudno\n",
      "Skipping non-plane route: Saqsaywaman -> Ollantaytambo\n",
      "Skipping non-plane route: Ollantaytambo -> Pisac Q'allaqasa\n",
      "Skipping non-plane route: Sittard -> Limbricht\n",
      "Skipping non-plane route: Limbricht -> Brussels\n",
      "Skipping non-plane route: Limbricht -> Paris\n",
      "Skipping non-plane route: Sittard -> Maastricht\n",
      "Skipping non-plane route: New York -> Evanston, IL\n",
      "Skipping non-plane route: Evanston, IL -> Missoula\n",
      "Skipping non-plane route: Missoula -> Seattle\n",
      "Skipping non-plane route: Seattle -> Olympia\n",
      "Skipping non-plane route: Olympia -> Vancouver\n",
      "Skipping non-plane route: Olympia -> Portland\n",
      "Skipping non-plane route: Burlington, VT -> Montreal\n",
      "Skipping non-plane route: Burlington, VT -> New York\n",
      "Skipping non-plane route: New York -> Washington, DC\n",
      "Skipping non-plane route: Burlington, VT -> New Orleans\n",
      "Processing plane route: Newark Airport -> Dublin Airport\n",
      "Great circle route saved to ../docs/resources/geojson/great_circle_route_57.geojson\n",
      "Updated Google Sheet with filename: great_circle_route_57.geojson\n",
      "Processing plane route: Dublin Airport -> Edinburgh Airport\n",
      "Great circle route saved to ../docs/resources/geojson/great_circle_route_58.geojson\n",
      "Updated Google Sheet with filename: great_circle_route_58.geojson\n"
     ]
    }
   ],
   "source": [
    "# airplane routes\n",
    "\n",
    "# calculate great circle route\n",
    "def calculate_great_circle(start_coords, end_coords, num_points=100):\n",
    "    geod = Geodesic.WGS84\n",
    "    line = geod.InverseLine(start_coords[0], start_coords[1], end_coords[0], end_coords[1])\n",
    "    \n",
    "    # intermediate points along the great circle\n",
    "    points = []\n",
    "    for i in range(num_points + 1):\n",
    "        s = i * line.s13 / num_points\n",
    "        position = line.Position(s)\n",
    "        points.append((position[\"lon2\"], position[\"lat2\"]))  # (longitude, latitude)\n",
    "    \n",
    "    return points\n",
    "\n",
    "# save as GeoJSON\n",
    "def save_great_circle_as_geojson(route_coords, output_file):\n",
    "    feature = geojson.Feature(\n",
    "        geometry=geojson.LineString(route_coords),\n",
    "        properties={\"transport_mode\": \"plane\"}\n",
    "    )\n",
    "    feature_collection = geojson.FeatureCollection([feature])\n",
    "    with open(output_file, \"w\") as f:\n",
    "        geojson.dump(feature_collection, f)\n",
    "    print(f\"Great circle route saved to {output_file}\")\n",
    "\n",
    "# process routes from Google Sheet\n",
    "def process_routes_from_sheet(route_data):\n",
    "    for index, row in route_data.iterrows():\n",
    "        transport_mode = row[\"transport_mode\"].lower()\n",
    "        start_location = row[\"start_location\"]\n",
    "        end_location = row[\"end_location\"]\n",
    "        filename = row.get(\"filename\", \"\").strip() \n",
    "\n",
    "        # check if \"plane\" and filename is empty\n",
    "        if transport_mode == \"plane\" and not filename:\n",
    "            print(f\"Processing plane route: {start_location} -> {end_location}\")\n",
    "\n",
    "            # geocode start and end locations\n",
    "            geolocator = Nominatim(user_agent=\"geoapi\", timeout=10)\n",
    "            start_coords = geolocator.geocode(start_location)\n",
    "            end_coords = geolocator.geocode(end_location)\n",
    "\n",
    "            if start_coords and end_coords:\n",
    "                # get latitude and longitude\n",
    "                start_coords = (start_coords.latitude, start_coords.longitude)\n",
    "                end_coords = (end_coords.latitude, end_coords.longitude)\n",
    "\n",
    "                # get great circle route\n",
    "                route_coords = calculate_great_circle(start_coords, end_coords)\n",
    "\n",
    "                # save as GeoJSON\n",
    "                filename = f\"great_circle_route_{index}.geojson\"\n",
    "                save_great_circle_as_geojson(route_coords, f\"../docs/resources/geojson/{filename}\")\n",
    "\n",
    "                # Update the Google Sheet with the filename, adjusting for 1-based index and header row\n",
    "                route_sheet.update_cell(index + 2, route_data.columns.get_loc(\"filename\") + 1, filename)\n",
    "                print(f\"Updated Google Sheet with filename: {filename}\")\n",
    "            else:\n",
    "                print(f\"Failed to geocode one or both locations: {start_location}, {end_location}\")\n",
    "        # else:\n",
    "            # print(f\"Skipping non-plane route: {start_location} -> {end_location}\")\n",
    "\n",
    "# call function to process routes\n",
    "process_routes_from_sheet(route_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generates Automobile routes, will fake a Train route with an auto route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to OpenRouteService API for automobile routes\n",
    "with open(\"api_keys.json\") as f:\n",
    "    api_keys = json.load(f)\n",
    "ors_client = openrouteservice.Client(key=api_keys[\"openrouteservice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# route function\n",
    "def fetch_route(start_coords, end_coords, transport_mode):\n",
    "    try:\n",
    "        profile = {\n",
    "            \"auto\": \"driving-car\",\n",
    "            # ORS doesn't support trains - find alterative API or method\n",
    "            \"train\": \"driving-car\",\n",
    "        }.get(transport_mode, \"driving-car\")\n",
    "\n",
    "        # request route from ors api\n",
    "        route = ors_client.directions(\n",
    "            coordinates=[start_coords, end_coords], profile=profile, format=\"geojson\"\n",
    "        )\n",
    "        return route\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch route for mode {transport_mode}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geocode coordinates a location\n",
    "def geocode_location(location):\n",
    "    try:\n",
    "        geocode_response = ors_client.pelias_search(text=location)\n",
    "        if geocode_response[\"features\"]:\n",
    "            coords = geocode_response[\"features\"][0][\"geometry\"][\"coordinates\"]\n",
    "            return coords[0], coords[1]  # Return (lon, lat)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to geocode location {location}: {e}\")\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process GeoJSON routes and save to file\n",
    "for index, row in route_data.iterrows():\n",
    "    # skip extant filenames\n",
    "    if pd.notna(row[\"filename\"]) and row[\"filename\"].strip() != \"\":\n",
    "        # print(f\"Skipping route {row['route_id']} as it already has a filename: {row['filename']}\")\n",
    "        continue\n",
    "\n",
    "    # geocode start and end locations\n",
    "    start_coords = geocode_location(row[\"start_location\"])\n",
    "    end_coords = geocode_location(row[\"end_location\"])\n",
    "\n",
    "    # if geocoding was successful, fetch the route\n",
    "    if None not in start_coords and None not in end_coords:\n",
    "        route = fetch_route(start_coords, end_coords, row[\"transport_mode\"])\n",
    "\n",
    "        # if route, save to GeoJSON file, update route_data df\n",
    "        if route:\n",
    "            geojson_filename = f\"{row['route_id']}.geojson\"\n",
    "            geojson_path = Path(\"../docs/resources/geojson/\") / geojson_filename\n",
    "\n",
    "            with open(geojson_path, \"w\") as f:\n",
    "                json.dump(route, f, indent=4)\n",
    "\n",
    "            route_data.at[index, \"filename\"] = geojson_filename\n",
    "            print(\n",
    "                f\"Generated GeoJSON for route {row['start_location']} to {row['end_location']}, and saved to {geojson_path}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to csv, updates google sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route data successfully saved to csv!\n"
     ]
    }
   ],
   "source": [
    "# save route data to csv\n",
    "route_data.to_csv(\"../docs/resources/data/routes.csv\", index=False)\n",
    "print(\"Route data successfully saved to csv!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route data successfully uploaded to Google Sheets!\n"
     ]
    }
   ],
   "source": [
    "# upload df back to google sheets\n",
    "set_with_dataframe(route_sheet, route_data)\n",
    "print(\"Route data successfully uploaded to Google Sheets!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
