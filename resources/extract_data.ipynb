{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import gspread\n",
    "import json\n",
    "import geojson\n",
    "import pandas as pd\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from geographiclib.geodesic import Geodesic\n",
    "import openrouteservice\n",
    "from geopy.geocoders import Nominatim\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following all export their respective Google sheet to JSON / CSV for the website, and updates the Google sheet if necessary.\n",
    "\n",
    "- [Overview](#overview) - Parses `photo` and `zoomBounds` if necessary.\n",
    "- [Activity](#activity) - Adds ID's. Generates latitude and longitude (`lat/lng`) coordinates, if activity lacks them.\n",
    "- [Location](#location) - Adds ID's. Generates latitude and longitude (`lat/lng`) coordinates, if location lacks them.\n",
    "- [Routes](#routes) - Add's ID's. Generates `lat/lng` coordinates, if missing. Adds hikes with JSON `route_path`. Generates Great Circle paths for airplane flights. Generates automobile routes (can be [manually set](#manual-coordinates)), and will simulate a train route using automobile routes.\n",
    "\n",
    "To update:\n",
    "\n",
    "**Overview** - Mostly manual. Can set `id` with `=ROW()-1`. `name` prominently shows up in popup and hover tooltip. Can use `./lat_lng_geopy.ipynb` for generating `lat` and `lng`, but it's probably easier to snag coordinates off of Google Maps. Haven't used `start_date` and `end_date` yet. `photo_album` and `photos` (structure as a python list) must contain the EXACT folder and filenames - capitalization matters. `description` and `notes` are optional and will display in the popup. `importance` is subjective and scales the marker size. Setting `visit_type` to \"school\" and `home` to TRUE styles the Waypoint marker border and adds popup icons. `zoomBounds` and `zoomLevel` are options for zooming from the popup.\n",
    "\n",
    "**Location** -  `location_id` auto-generates. `name` prominently shows up in popup and hover tooltip. The `location` field is used to generate `lat` and `lng` if empty. `description` and `notes` are optional and will display in the popup.\n",
    "\n",
    "**Activity** - `activity_id` auto-generates. `name` prominently shows up in popup and hover tooltip. The `location` field is used to generate `lat` and `lng` if empty. `activity_type` must match the icon list in `../docs/static/js/overlays.js`. `route_path` enables the Routes layer on zoom, and auto-populates the Routes sheet for hiking. `description` and `notes` are optional and will display in the popup. `photo_album` and `photos` (structure as a python list) must contain the EXACT folder and filenames - capitalization matters.\n",
    "\n",
    "**Routes** - `route_id` auto-generates. The `start_location` and `end_location` fileds are used to auto-generate routes. `transport_mode` determines route generation and display and only accepts the following values: `auto`, `plane`, `boat`, `train`, and `hike`. `filename` auto-generates for `auto`, `plane` and `hike` routes.\n",
    "- **hike** - Automatically added from the Activity sheet if there is a `route_path`. Can also be manually added. Use an [Overpass Turbo](https://overpass-turbo.eu/) query to find trails.\n",
    "- **plane** - Automatically generates Great Circle routes that cross the international date line. Recommend ensuring that `start_location` and `end_location` are airports.\n",
    "- **auto** - Automatically generated, but amy be finicky about geocoding `start_location` and `end_location`. Can manually set start and end `lat/lng` [here](#manual-coordinates).\n",
    "- **train** - Muse be manually added. Use an [Overpass Turbo](https://overpass-turbo.eu/) query to find train routes. Use `./trim_geojson.ipynb` to edit GeoJSON files. The program will generate an automobile route styled to resemble a train route if one is not manually added.\n",
    "- **boat** - Muse be manually added. Use an [Overpass Turbo](https://overpass-turbo.eu/) query to find ferry routes, or draw with [geojson.io](https://geojson.io/). Use `./trim_geojson.ipynb` to edit Overpass Turbo routes.\n",
    "- N.B., I try to store Overpass Turbo routes in `./overpass_routes.ipynb` for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authenticate and connect to google sheets\n",
    "scope = [\n",
    "    \"https://spreadsheets.google.com/feeds\",\n",
    "    \"https://www.googleapis.com/auth/drive\",\n",
    "]\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(\"api_keys.json\", scope)\n",
    "client = gspread.authorize(creds)\n",
    "spreadsheet = client.open_by_key(\"12L4EkdRqaQ_e42fGHWaTmgCeqQrNgjTfoeAEc5AB6tw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "[Back to Top](#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from google sheet\n",
    "overview_sheet = spreadsheet.worksheet(\"Overview\")\n",
    "overview_data = overview_sheet.get_all_records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert photo lists stored as strings into actual lists\n",
    "def parse_photo_list(value):\n",
    "    if isinstance(value, str) and value.strip():\n",
    "        return [item.strip() for item in value.split(\",\")]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse zoomBounds if it's stored as a string\n",
    "def parse_zoom_bounds(value):\n",
    "    import json\n",
    "    if isinstance(value, str) and value.strip():\n",
    "        try:\n",
    "            # parse the string as JSON\n",
    "            return json.loads(value)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Invalid zoomBounds format: {value}\")\n",
    "    return None  # if parsing fails or value is empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data\n",
    "for entry in overview_data:\n",
    "    # parse and clean up photos list\n",
    "    raw_photos = entry.get(\"photos\", \"\")\n",
    "    entry[\"photos\"] = [photo.strip('[]\"') for photo in parse_photo_list(raw_photos)]\n",
    "\n",
    "    # parse zoomBounds into a proper list\n",
    "    raw_zoom_bounds = entry.get(\"zoomBounds\", \"\")\n",
    "    entry[\"zoomBounds\"] = parse_zoom_bounds(raw_zoom_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travel data successfully saved!\n"
     ]
    }
   ],
   "source": [
    "# save as JSON for JavaScript map\n",
    "with open(\"../docs/resources/data/overview.json\", \"w\") as file:\n",
    "    json.dump(overview_data, file, indent=2)\n",
    "\n",
    "print(\"Travel data successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity\n",
    "\n",
    "[Back to Top](#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Activity data\n",
    "activity_sheet = spreadsheet.worksheet(\"Activity\")\n",
    "activity_data = pd.DataFrame(activity_sheet.get_all_records())\n",
    "\n",
    "# add activity IDs\n",
    "activity_data[\"activity_id\"] = [\n",
    "    str(uuid.uuid4()) if pd.isna(id) or id == \"\" else id\n",
    "    for id in activity_data.get(\"activity_id\", [])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geocode locations missing lat/lng\n",
    "geolocator = Nominatim(user_agent=\"geoapi\", timeout=10)\n",
    "\n",
    "# cache for geocoding results, to avoid repeated requests / rate limits\n",
    "try:\n",
    "    with open(\"./geocode_cache.json\", \"r\") as cache_file:\n",
    "        geocode_cache = json.load(cache_file)\n",
    "except FileNotFoundError:\n",
    "    geocode_cache = {}\n",
    "\n",
    "\n",
    "def geocode_activity_location(location_name):\n",
    "    # check cache first\n",
    "    if location_name in geocode_cache:\n",
    "        return geocode_cache[location_name][\"lat\"], geocode_cache[location_name][\"lng\"]\n",
    "    try:\n",
    "        location = geolocator.geocode(location_name)\n",
    "        if location:\n",
    "            lat_lng = {\"lat\": location.latitude, \"lng\": location.longitude}\n",
    "            geocode_cache[location_name] = lat_lng  # cache result\n",
    "            return lat_lng[\"lat\"], lat_lng[\"lng\"]\n",
    "        else:\n",
    "            print(f\"No lat/lng found for location: {location_name}\")\n",
    "            return pd.Series([None, None])\n",
    "    except Exception as e:\n",
    "        print(f\"Error geocoding {location_name}: {e}\")\n",
    "        return pd.Series([None, None])\n",
    "\n",
    "\n",
    "# geocode if lat/lng are missing\n",
    "for index, row in activity_data.iterrows():\n",
    "    if not row[\"lat\"] or not row[\"lng\"] or pd.isna(row[\"lat\"]) or pd.isna(row[\"lng\"]):\n",
    "        lat, lng = geocode_activity_location(row[\"location\"])\n",
    "        print(f\"Geocoding {row['location']}...\")\n",
    "        activity_data.at[index, \"lat\"] = lat\n",
    "        activity_data.at[index, \"lng\"] = lng\n",
    "\n",
    "        # save progress every 5 requests\n",
    "        if index % 5 == 0:\n",
    "            with open(\"./geocode_cache.json\", \"w\") as cache_file:\n",
    "                json.dump(geocode_cache, cache_file)\n",
    "\n",
    "        # for Nominatim rate limits\n",
    "        # sleep(1)\n",
    "\n",
    "# save final cache\n",
    "with open(\"./geocode_cache.json\", \"w\") as cache_file:\n",
    "    json.dump(geocode_cache, cache_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity data successfully saved to csv!\n"
     ]
    }
   ],
   "source": [
    "# save updated data to csv for JavaScript map\n",
    "activity_data.to_csv(\"../docs/resources/data/activity.csv\", index=False)\n",
    "\n",
    "print(\"Activity data successfully saved to csv!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity data successfully uploaded to Google Sheets!\n"
     ]
    }
   ],
   "source": [
    "# upload updated data to Google Sheets\n",
    "\n",
    "# replace NaN or None values with empty strings for Google Sheets compatibility\n",
    "activity_data = activity_data.fillna(\"\")\n",
    "\n",
    "# convert df to lists of lists\n",
    "activity_data_list = [\n",
    "    activity_data.columns.values.tolist()\n",
    "] + activity_data.values.tolist()\n",
    "\n",
    "# upload Activity sheet\n",
    "activity_sheet = spreadsheet.worksheet(\"Activity\")\n",
    "try:\n",
    "    activity_sheet.clear()  # clear existing data\n",
    "    activity_sheet.update(values=activity_data_list, range_name=\"A1\")  # upload new data\n",
    "except Exception as e:\n",
    "    print(f\"Error updating Activity sheet: {e}\")\n",
    "\n",
    "print(\"Activity data successfully uploaded to Google Sheets!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location\n",
    "\n",
    "[Back to top](#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Location data\n",
    "location_sheet = spreadsheet.worksheet(\"Location\")\n",
    "location_data = pd.DataFrame(location_sheet.get_all_records())\n",
    "\n",
    "# add location IDs\n",
    "location_data[\"location_id\"] = [\n",
    "    str(uuid.uuid4()) if pd.isna(id) or id == \"\" else id\n",
    "    for id in location_data.get(\"location_id\", [])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geocode if lat/lng are missing\n",
    "for index, row in location_data.iterrows():\n",
    "    if not row[\"lat\"] or not row[\"lng\"] or pd.isna(row[\"lat\"]) or pd.isna(row[\"lng\"]):\n",
    "        lat, lng = geocode_activity_location(row[\"location\"])\n",
    "        print(f\"Geocoding {row['location']}...\")\n",
    "        location_data.at[index, \"lat\"] = lat\n",
    "        location_data.at[index, \"lng\"] = lng\n",
    "\n",
    "        # save progress every 5 requests\n",
    "        if index % 5 == 0:\n",
    "            with open(\"./geocode_cache.json\", \"w\") as cache_file:\n",
    "                json.dump(geocode_cache, cache_file)\n",
    "\n",
    "        # for Nominatim rate limits\n",
    "        # sleep(1)\n",
    "\n",
    "# save final cache\n",
    "with open(\"./geocode_cache.json\", \"w\") as cache_file:\n",
    "    json.dump(geocode_cache, cache_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location data successfully saved to csv!\n"
     ]
    }
   ],
   "source": [
    "# save updated data to csv for JavaScript map\n",
    "location_data.to_csv(\"../docs/resources/data/locations.csv\", index=False)\n",
    "\n",
    "print(\"Location data successfully saved to csv!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location data successfully uploaded to Google Sheets!\n"
     ]
    }
   ],
   "source": [
    "# upload updated data to Google Sheets\n",
    "\n",
    "# replace NaN or None values with empty strings for Google Sheets compatibility\n",
    "location_data = location_data.fillna(\"\")\n",
    "\n",
    "# convert df to lists of lists\n",
    "location_data_list = [\n",
    "    location_data.columns.values.tolist()\n",
    "] + location_data.values.tolist()\n",
    "\n",
    "# upload Location sheet\n",
    "location_sheet = spreadsheet.worksheet(\"Location\")\n",
    "try:\n",
    "    location_sheet.clear()  # clear existing data\n",
    "    location_sheet.update(values=location_data_list, range_name=\"A1\")  # upload new data\n",
    "except Exception as e:\n",
    "    print(f\"Error updating Location sheet: {e}\")\n",
    "\n",
    "print(\"Location data successfully uploaded to Google Sheets!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Routes\n",
    "\n",
    "[Back to top](#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load route data\n",
    "route_sheet = spreadsheet.worksheet(\"Routes\")\n",
    "route_data = pd.DataFrame(route_sheet.get_all_records())\n",
    "\n",
    "# cache for geocoding results, to avoid repeated requests / rate limits\n",
    "try:\n",
    "    with open(\"./geocode_cache_routes.json\", \"r\") as cache_file:\n",
    "        geocode_cache_routes = json.load(cache_file)\n",
    "except FileNotFoundError:\n",
    "    geocode_cache_routes = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Hike routes if in Activity and with a geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Activity geojson to Routes\n",
    "for index, row in activity_data.iterrows():\n",
    "    # if hiking activities with a route_path not in Routes.filename\n",
    "    if (\n",
    "        row[\"activity_type\"] == \"hiking\"  # Activity type is hiking\n",
    "        and row[\"route_path\"]  # Activity has a route_path\n",
    "        and row[\"route_path\"] not in route_data[\"filename\"].values  # route_path not in Routes.filename\n",
    "    ):\n",
    "        # add new route to Routes\n",
    "        new_route = {\n",
    "            \"start_location\": row[\"name\"],  # Activity.name\n",
    "            \"end_location\": row[\"name\"],  # Activity.name\n",
    "            \"transport_mode\": \"hike\",  # Fixed value\n",
    "            \"filename\": row[\"route_path\"],  # Activity.route_path\n",
    "        }\n",
    "        route_data = pd.concat([route_data, pd.DataFrame([new_route])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add route IDs\n",
    "route_data[\"route_id\"] = [\n",
    "    str(uuid.uuid4()) if pd.isna(id) or id == \"\" else id\n",
    "    for id in route_data.get(\"route_id\", [])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generates Airplane great circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# airplane routes\n",
    "\n",
    "# calculate great circle route\n",
    "def calculate_great_circle(start_coords, end_coords, num_points=100):\n",
    "    geod = Geodesic.WGS84\n",
    "    line = geod.InverseLine(start_coords[0], start_coords[1], end_coords[0], end_coords[1])\n",
    "    \n",
    "    # intermediate points along the great circle\n",
    "    points = []\n",
    "    for i in range(num_points + 1):\n",
    "        s = i * line.s13 / num_points\n",
    "        position = line.Position(s)\n",
    "        lon, lat = position[\"lon2\"], position[\"lat2\"]\n",
    "        \n",
    "        # handle crossing the International Date Line\n",
    "        if points and abs(lon - points[-1][0]) > 180:\n",
    "            if lon > 0:\n",
    "                lon -= 360  # shift longitude from +180 to -180\n",
    "            else:\n",
    "                lon += 360  # shift longitude from -180 to +180\n",
    "        \n",
    "        points.append((lon, lat))  # (longitude, latitude)\n",
    "    \n",
    "    return points\n",
    "\n",
    "# save as GeoJSON\n",
    "def save_great_circle_as_geojson(route_coords, output_file):\n",
    "    feature = geojson.Feature(\n",
    "        geometry=geojson.LineString(route_coords),\n",
    "        properties={\"transport_mode\": \"plane\"}\n",
    "    )\n",
    "    feature_collection = geojson.FeatureCollection([feature])\n",
    "    with open(output_file, \"w\") as f:\n",
    "        geojson.dump(feature_collection, f)\n",
    "    print(f\"Great circle route saved to {output_file}\")\n",
    "\n",
    "# process routes from Google Sheet\n",
    "def process_plane_routes_from_sheet(route_data):\n",
    "    for index, row in route_data.iterrows():\n",
    "        transport_mode = row[\"transport_mode\"].lower()\n",
    "        start_location = row[\"start_location\"]\n",
    "        end_location = row[\"end_location\"]\n",
    "        filename = row.get(\"filename\", \"\").strip() \n",
    "\n",
    "        # check if \"plane\" and filename is empty\n",
    "        if transport_mode == \"plane\" and not filename:\n",
    "            print(f\"Processing plane route: {start_location} -> {end_location}\")\n",
    "\n",
    "            # check if start and end locations are in cache\n",
    "            start_coords = geocode_cache_routes.get(start_location)\n",
    "            end_coords = geocode_cache_routes.get(end_location)\n",
    "\n",
    "            # if not in cache, geocode the locations, add location to cache\n",
    "            if not start_coords:\n",
    "                geolocator = Nominatim(user_agent=\"geoapi\", timeout=10)\n",
    "                location = geolocator.geocode(start_location)\n",
    "                if location:\n",
    "                    start_coords = (location.latitude, location.longitude)\n",
    "                    geocode_cache_routes[start_location] = start_coords  # cache result\n",
    "                else:\n",
    "                    print(f\"Failed to geocode start location: {start_location}\")\n",
    "                    continue\n",
    "\n",
    "            if not end_coords:\n",
    "                geolocator = Nominatim(user_agent=\"geoapi\", timeout=10)\n",
    "                location = geolocator.geocode(end_location)\n",
    "                if location:\n",
    "                    end_coords = (location.latitude, location.longitude)\n",
    "                    geocode_cache_routes[end_location] = end_coords  # cache result\n",
    "                else:\n",
    "                    print(f\"Failed to geocode end location: {end_location}\")\n",
    "                    continue\n",
    "\n",
    "            # get great circle route\n",
    "            route_coords = calculate_great_circle(start_coords, end_coords)\n",
    "\n",
    "            # save as GeoJSON\n",
    "            filename = f\"great_circle_route_{index}.geojson\"\n",
    "            save_great_circle_as_geojson(route_coords, f\"../docs/resources/geojson/{filename}\")\n",
    "\n",
    "            # update route_data with geojson filename\n",
    "            route_data.at[index, \"filename\"] = filename\n",
    "            print(f\"Updated Google Sheet with filename: {filename}\")\n",
    "\n",
    "    # save updated cache to file\n",
    "    with open(\"./geocode_cache_routes.json\", \"w\") as cache_file:\n",
    "        json.dump(geocode_cache_routes, cache_file)\n",
    "\n",
    "# call function to process routes\n",
    "process_plane_routes_from_sheet(route_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generates Automobile routes, will fake a Train route with an auto route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to OpenRouteService API for automobile routes\n",
    "with open(\"api_keys.json\") as f:\n",
    "    api_keys = json.load(f)\n",
    "ors_client = openrouteservice.Client(key=api_keys[\"openrouteservice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# route function\n",
    "def fetch_route(start_coords, end_coords, transport_mode):\n",
    "    try:\n",
    "        profile = {\n",
    "            \"auto\": \"driving-car\",\n",
    "            # ORS doesn't support trains - find alterative API or method\n",
    "            \"train\": \"driving-car\",\n",
    "        }.get(transport_mode, \"driving-car\")\n",
    "\n",
    "        # request route from ors api\n",
    "        route = ors_client.directions(\n",
    "            coordinates=[start_coords, end_coords], profile=profile, format=\"geojson\"\n",
    "        )\n",
    "        return route\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch route for mode {transport_mode}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geocode coordinates a location\n",
    "def geocode_route_location(location):\n",
    "    # check cache first\n",
    "    if location in geocode_cache_routes:\n",
    "        return geocode_cache_routes[location]\n",
    "    try:\n",
    "        geocode_response = ors_client.pelias_search(text=location)\n",
    "        if geocode_response[\"features\"]:\n",
    "            coords = geocode_response[\"features\"][0][\"geometry\"][\"coordinates\"]\n",
    "            geocode_cache_routes[location] = (coords[0], coords[1])  # cache result\n",
    "            return coords[0], coords[1]  # return (lon, lat)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to geocode location {location}: {e}\")\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Coordinates\n",
    "\n",
    "[Back to top](#)\n",
    "\n",
    "In the following dictionary, manually set the start_location and end_location coordinates. The name must match the spreadsheet location exactly. \n",
    "\n",
    "#### <b>Format: (longitude, latitude)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually set lng/lat here\n",
    "locations = {\n",
    "    \"Fish River Canyon\": (17.614818, -27.589350),  # Fish River Canyon\n",
    "    \"N7 to Noordoewer Border Post\": (17.830023, -29.020174),\n",
    "    \"N7 again to Noordoewer Border Post\": (17.697956, -28.843831),\n",
    "    \"Border Posts - Vioolsdrift\": (17.626150, -28.770706),\n",
    "    \"Sesriem\": (15.803785, -24.491391),  # Sesriem\n",
    "    \"Sesriem Canyon\": (15.803785, -24.491391),  # Sesriem Canyon\n",
    "    \"Kokerboomwoud\": (18.241756, -26.481496),  # Kokerboomwoud\n",
    "    \"Deadvlei\": (15.322147, -24.729733),  # Deadvlei\n",
    "    \"Dune 45\": (15.471035, -24.723004),  # Dune 45\n",
    "    \"Giant's Playground\": (18.270635, -26.464834),  # Giant's Playground\n",
    "    \"Keetmanshoop\": (18.138505, -26.585550),  # Keetmanshoop\n",
    "    \"Helmeringhausen\": (16.821412, -25.889119),  # Helmeringhausen\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process GeoJSON routes and save to file\n",
    "for index, row in route_data.iterrows():\n",
    "    # skip extant filenames\n",
    "    if pd.notna(row[\"filename\"]) and row[\"filename\"].strip() != \"\":\n",
    "        # print(f\"Skipping route {row['route_id']} as it already has a filename: {row['filename']}\")\n",
    "        continue\n",
    "\n",
    "    # check if start_location and end_location exist in the manually set locations, default to geocode\n",
    "    start_coords = locations.get(row[\"start_location\"], geocode_route_location(row[\"start_location\"]))\n",
    "    end_coords = locations.get(row[\"end_location\"], geocode_route_location(row[\"end_location\"]))\n",
    "\n",
    "    # if geocoding was successful, fetch the route\n",
    "    if None not in start_coords and None not in end_coords:\n",
    "        route = fetch_route(start_coords, end_coords, row[\"transport_mode\"])\n",
    "\n",
    "        # if route, save to GeoJSON file, update route_data df\n",
    "        if route:\n",
    "            geojson_filename = f\"{row['route_id']}.geojson\"\n",
    "            geojson_path = Path(\"../docs/resources/geojson/\") / geojson_filename\n",
    "\n",
    "            with open(geojson_path, \"w\") as f:\n",
    "                json.dump(route, f, indent=4)\n",
    "\n",
    "            route_data.at[index, \"filename\"] = geojson_filename\n",
    "            print(\n",
    "                f\"Generated GeoJSON for route {row['start_location']} to {row['end_location']}, and saved to {geojson_path}\"\n",
    "            )\n",
    "\n",
    "# save updated cache to file\n",
    "with open(\"./geocode_cache_routes.json\", \"w\") as cache_file:\n",
    "    json.dump(geocode_cache_routes, cache_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to csv, updates google sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route data successfully saved to csv!\n"
     ]
    }
   ],
   "source": [
    "# save route data to csv\n",
    "route_data.to_csv(\"../docs/resources/data/routes.csv\", index=False)\n",
    "print(\"Route data successfully saved to csv!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route data successfully uploaded to Google Sheets!\n"
     ]
    }
   ],
   "source": [
    "# upload df back to google sheets\n",
    "set_with_dataframe(route_sheet, route_data)\n",
    "print(\"Route data successfully uploaded to Google Sheets!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
